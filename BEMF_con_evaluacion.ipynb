{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8b2b3c",
   "metadata": {},
   "source": [
    "## Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d178245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f374d",
   "metadata": {},
   "source": [
    "## Código modelo de factorización matricial de Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98424b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    try:\n",
    "        return 1 / (1 + exp(-x))\n",
    "    except:\n",
    "        # print(f\"Cannot calculate the sigmoid function for x={x}. Rounding to {1 if x > 0 else 0}\")\n",
    "        return 1 if x > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_gradient(prev_value, is_one_hot: bool, dot: float, item):\n",
    "    return prev_value + (1 - sigmoid(dot)) * item if is_one_hot else prev_value - sigmoid(dot) * item\n",
    "\n",
    "\n",
    "def update_factor(element, gradient, learning_rate: float, regularisation: float):\n",
    "    return element + learning_rate * (gradient - regularisation * element)\n",
    "\n",
    "\n",
    "class BeMF:\n",
    "    num_factors = num_iters = 0\n",
    "    learning_rate = regularisation = 0.0\n",
    "    possible_scores = []  # eg. 1,2,3,4,5\n",
    "    U = [[[]]]  # User-factor matrices for each score\n",
    "    V = [[[]]]  # Item-factor matrices for each score\n",
    "    user_ids = []  # All the different users\n",
    "    item_ids = []  # All the different items\n",
    "    number_of_users = 0\n",
    "    number_of_items = 0\n",
    "    ratings = [[]] # The matrix for each user-item combination with the score if the user rated it and None if not\n",
    "    __cached_MAE = -1 # Caches the MAE result. Reset upon .fit() calls\n",
    "    predictions_matrix = [[]] # The prediction given for each user-item combination\n",
    "\n",
    "    def __init__(self, possible_scores: [], user_item_rating_matrix: [[]], user_ids: [], item_ids: [], num_factors: int, num_iters: int, learning_rate: int, regularisation: int, seed: int, verbose=True):\n",
    "        self.num_factors = num_factors\n",
    "        self.num_iters = num_iters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularisation = regularisation\n",
    "        self.possible_scores = possible_scores\n",
    "        self.user_ids = user_ids\n",
    "        self.number_of_users = len(user_ids)\n",
    "        self.item_ids = item_ids\n",
    "        self.number_of_items = len(item_ids)\n",
    "        self.ratings = user_item_rating_matrix\n",
    "        random.seed(seed)\n",
    "\n",
    "        self.U = [[[random.random() for _ in range(num_factors)] for _ in user_ids] for _ in possible_scores]\n",
    "        self.V = [[[random.random() for _ in range(num_factors)] for _ in item_ids] for _ in possible_scores]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"*BeMF model setup completed*\")\n",
    "            self.print_status()\n",
    "\n",
    "    def print_status(self):\n",
    "        print(f\"num_factors:\\t{self.num_factors}\")\n",
    "        print(f\"num_iters:\\t{self.num_iters}\")\n",
    "        print(f\"learning_rate:\\t{self.learning_rate}\")\n",
    "        print(f\"regularisation:\\t{self.regularisation}\")\n",
    "        print(f\"possible_scores:\\t{self.possible_scores}\")\n",
    "        print(f\"user_ids:\\t{len(self.user_ids)}\")\n",
    "        print(f\"item_ids:\\t{len(self.item_ids)}\")\n",
    "        print(f\"ratings:\\t({len(self.ratings)}, {len(self.ratings[0])})\")\n",
    "        print(f\"U:\\t({len(self.U)}, {len(self.U[0])}, {len(self.U[0][0])})\")\n",
    "        print(f\"V:\\t({len(self.V)}, {len(self.V[0])}, {len(self.V[0][0])})\")\n",
    "\n",
    "\n",
    "    def fit(self, verbose=False, make_predictions_matrix=False):\n",
    "        for i in range(1, self.num_iters+1):\n",
    "            self.__cached_MAE = -1\n",
    "            for s in range(len(self.possible_scores)):\n",
    "                score = self.possible_scores[s]\n",
    "                for user_index in range(self.number_of_users):\n",
    "                    self.__update_users_factors(user_index, self.U[s], self.V[s], score)\n",
    "                for item_index in range(self.number_of_items):\n",
    "                    self.__update_items_factors(item_index, self.U[s], self.V[s], score)\n",
    "            if verbose:\n",
    "                self.__print_current_iteration(i)\n",
    "        if make_predictions_matrix:\n",
    "            self.make_predictions_matrix()\n",
    "        if verbose:\n",
    "            print(\"Training concluded\")\n",
    "\n",
    "\n",
    "    def __print_current_iteration(self, i: int):\n",
    "        if i == 1:\n",
    "            print(\"Starting fitting process. Please wait.\")\n",
    "            return\n",
    "        if (i % 10) == 0:\n",
    "            print(f\"\\t{i} iterations - MAE: {self.evaluate_MAE()}\")\n",
    "            return\n",
    "        print(\".\", end=\"\")\n",
    "\n",
    "    \n",
    "    def evaluate_MAE(self):\n",
    "        \"\"\"Calculates the Mean Absolute Error (MAE) of the model. The value should get closer to 0 as the training advances.\n",
    "\n",
    "        Returns:\n",
    "            float: The result of the calculations\n",
    "        \"\"\"\n",
    "        if self.__cached_MAE < 0:\n",
    "            pred_df = pd.DataFrame(self.make_predictions_matrix()).fillna(0)\n",
    "            real_df = pd.DataFrame(self.ratings).fillna(0)\n",
    "            self.__cached_MAE = mean_absolute_error(real_df, pred_df)\n",
    "        return self.__cached_MAE\n",
    "\n",
    "\n",
    "    def make_predictions_matrix(self):\n",
    "        self.predictions_matrix = np.array([np.array([self.predict(user_index, item_index, False)\n",
    "                                            for item_index in range(self.number_of_items)])\n",
    "                                            for user_index in range(self.number_of_users)])\n",
    "        return self.predictions_matrix\n",
    "\n",
    "\n",
    "\n",
    "    def __update_users_factors(self, user_index: int, U: [[]], V: [[]], score: int):\n",
    "        gradients = [0] * self.num_factors\n",
    "\n",
    "        for item_index in range(len(V)):\n",
    "            if not self.ratings[user_index][item_index]:\n",
    "                continue  # Not rated, skip\n",
    "            is_one_hot = self.ratings[user_index][item_index] == score\n",
    "            dot_product = np.dot(U[user_index], V[item_index])\n",
    "            gradients = [calculate_gradient(gradients[k], is_one_hot, dot_product, V[item_index][k]) for k in range(self.num_factors)]\n",
    "        \n",
    "        U[user_index] = [update_factor(U[user_index][k], gradients[k], self.learning_rate, self.regularisation) for k in range(self.num_factors)]\n",
    "\n",
    "\n",
    "    def __update_items_factors(self, item_index: int, U: [[]], V: [[]], score: int):\n",
    "        gradients = [0] * self.num_factors\n",
    "\n",
    "        for user_index in range(len(U)):\n",
    "            if not self.ratings[user_index][item_index]:\n",
    "                continue  # Not rated, skip\n",
    "            is_one_hot = self.ratings[user_index][item_index] == score\n",
    "            dot_product = np.dot(U[user_index], V[item_index])\n",
    "            gradients = [calculate_gradient(gradients[k], is_one_hot, dot_product, U[user_index][k]) for k in range(self.num_factors)]\n",
    "\n",
    "        V[item_index] = [update_factor(V[item_index][k], gradients[k], self.learning_rate, self.regularisation) for k in range(self.num_factors)]\n",
    "\n",
    "\n",
    "    def get_probability(self, user_index: int, item_index: int, score_index):\n",
    "        \"\"\"Calculate the probability of the user rating the item with the given score_index\n",
    "\n",
    "        Args:\n",
    "\n",
    "            `score_index` (int): Index of the score present in `possible_scores`\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            float: The calculated probability\n",
    "        \"\"\"\n",
    "        if score_index >= len(self.possible_scores):\n",
    "            return f\"Error: index {score_index} out of range {len(self.possible_scores)}\"\n",
    "        dot_product = sigmoid(np.dot(self.U[score_index][user_index], self.V[score_index][item_index]))\n",
    "        sum = 0.0\n",
    "\n",
    "        for i in range(len(self.possible_scores)):\n",
    "            sum += sigmoid(np.dot(self.U[i][user_index], self.V[i][item_index]))\n",
    "\n",
    "        try:\n",
    "            return dot_product/sum\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def predict(self, user_index: int, item_index: int, use_cached_results: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "            `use_cached_results` (bool): If False forces recalculation of values\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            int: the score most likely to be given by the user at `user_index` to the item at `item_index`\n",
    "        \"\"\"\n",
    "        if user_index >= len(self.U[0]):\n",
    "            return f\"Error: index {user_index} out of range {len(self.U[0])}\"\n",
    "        if item_index >= len(self.V[0]):\n",
    "            return f\"Error: index {item_index} out of range {len(self.V[0])}\"\n",
    "        if use_cached_results:\n",
    "            return self.predictions_matrix[user_index][item_index]\n",
    "\n",
    "        maximum = self.get_probability(user_index, item_index, 0)\n",
    "        index = 0\n",
    "\n",
    "        for r in range(1, len(self.possible_scores)):\n",
    "            probability = self.get_probability(user_index, item_index, r)\n",
    "            if (maximum < probability):\n",
    "                maximum = probability\n",
    "                index = r\n",
    "        \n",
    "        return self.possible_scores[index]\n",
    "\n",
    "\n",
    "    def predict_proba(self, user_index: int, item_index: int):\n",
    "        prediction = self.predict(user_index, item_index)\n",
    "        return self.get_probability(user_index, item_index, self.possible_scores.index(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb5d3f",
   "metadata": {},
   "source": [
    "# Importamos los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f93b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datos = pd.read_excel('C:/Users/amidonga/Documents/TFG/Datos_Sinteticos_CON_TRAMITES.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3892dc",
   "metadata": {},
   "source": [
    "### Corrección de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos 0 por 1 y 1 por 2\n",
    "for columna in ['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']:\n",
    "    df_datos[columna] = df_datos[columna] +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb0679",
   "metadata": {},
   "source": [
    "### Calculamos los n usuarios más parecidos a un usuario concreto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301017b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_usuarios_similares(df, usuario_concreto, n):\n",
    "    # Filtrar el dataframe por las características relevantes para el cálculo de similitud\n",
    "    features = ['Edad', 'Procedencia', 'Sexo', 'Situación de dependencia', 'Sector económico',\n",
    "                'Renta anual neta', 'Estado civil', 'Número de hijos']\n",
    "    df_filt = df[features].copy()\n",
    "\n",
    "    # Codificar las variables categóricas utilizando one-hot encoding\n",
    "    df_encoded = pd.get_dummies(df_filt)\n",
    "    # Obtener el índice del usuario concreto\n",
    "    idx_usuario_concreto = df_filt.index[df_filt.index == usuario_concreto]\n",
    "    \n",
    "    # Calcular la similitud del coseno entre el usuario concreto y todos los demás usuarios\n",
    "    similarities = cosine_similarity(df_encoded.iloc[idx_usuario_concreto], df_encoded)\n",
    "\n",
    "    # Obtener los índices de los usuarios más similares (excluyendo al usuario concreto)\n",
    "    similar_users_indices = np.argsort(similarities[0])[::-1][:n]\n",
    "    \n",
    "    # Agregar el índice del usuario concreto al conjunto de usuarios similares\n",
    "    #similar_users_indices = np.concatenate((idx_usuario_concreto, similar_users_indices))\n",
    "\n",
    "    # Obtener los datos de los usuarios más similares\n",
    "    similar_users = df.loc[similar_users_indices]\n",
    "\n",
    "    return similar_users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee58c1b6",
   "metadata": {},
   "source": [
    "### Función para preparar la matriz de valoraciones a partir del dataframe de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_ratings_matrix(df):    \n",
    "    # Obtén el número de filas y columnas\n",
    "    num_rows, num_cols = df.shape\n",
    "    # Crea una matriz de tamaño adecuado, inicializada con None\n",
    "    ratings_matrix = np.full((num_rows, num_cols),None, dtype=object)\n",
    "\n",
    "    # Itera sobre las filas del dataframe\n",
    "    for row_idx, row in df.iterrows():\n",
    "        # Itera sobre las columnas del dataframe\n",
    "        for col_idx, col_label in enumerate(df.columns):\n",
    "            # Obtiene el valor de la celda\n",
    "            value = row[col_label]\n",
    "            # Si el valor no es NaN, colócalo en la matriz\n",
    "            if not pd.isnull(value):\n",
    "                ratings_matrix[row_idx, col_idx] = int(value)\n",
    "        \n",
    "    return ratings_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee5bdb1",
   "metadata": {},
   "source": [
    "# Ejemplo de uso concreto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f808527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BIEN la valoración es 1 ->0\n",
    "\n",
    "\n",
    "usuario= 3 \n",
    "item = 2  #empieza en 0 para predict 1=0\n",
    "# Calculamos los 200 usuarios más similares al usuario elegido.\n",
    "usuarios_similares = calcular_usuarios_similares(df_datos, usuario_concreto = usuario, n=200)\n",
    "\n",
    "# Creamos la matriz de valoraciones de estos usuarios\n",
    "df_ratings_matrix = usuarios_similares[['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']]\n",
    "df_ratings_matrix.reset_index(inplace=True)\n",
    "df_ratings_matrix=df_ratings_matrix[['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']]\n",
    "ratings_matrix_u=crear_ratings_matrix(df_ratings_matrix)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo\n",
    "possible_scores = [1,2]\n",
    "user_ids = list(range(0,200))  # Lista de ID de usuarios\n",
    "item_ids = [1,2,3,4,5,6,7]  # Lista de ID de elementos\n",
    "num_factors = 10\n",
    "num_iters = 200\n",
    "learning_rate = 0.02\n",
    "regularisation = 0.1\n",
    "seed = 42\n",
    "\n",
    "bemf_model = BeMF(possible_scores, ratings_matrix_u, user_ids, item_ids, num_factors, num_iters, learning_rate, regularisation, seed)\n",
    "    \n",
    "# Actualizaciones del proceso\n",
    "bemf_model.fit(verbose=True)\n",
    "\n",
    "# predicción \n",
    "prediction = bemf_model.predict(0, item-1)\n",
    "\n",
    "probabilidad = round(bemf_model.get_probability(0, item-1,prediction-1),4)\n",
    "\n",
    "print('La predicción para el usuario',usuario,'y el item',item,'es la valoración',prediction-1,'con probabilidad',probabilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eeaf38",
   "metadata": {},
   "source": [
    "# Función para automatizar la predicción "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d31939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion(usuario,item, df_para_usuarios_similares): # usuarios de 0 a n (indices tabla).  Item 0 se corresponde con el 1\n",
    "    # Tomamos los 200 usuarios más similares a él\n",
    "    usuarios_similares = calcular_usuarios_similares(df_para_usuarios_similares, usuario_concreto = usuario, n=350)\n",
    "    df_ratings_matrix = usuarios_similares[['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']]\n",
    "    df_ratings_matrix.reset_index(inplace=True)\n",
    "    df_ratings_matrix=df_ratings_matrix[['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']]\n",
    "    \n",
    "    # Creamos la matriz asociada a este dataframe\n",
    "    ratings_matrix_u=crear_ratings_matrix(df_ratings_matrix)\n",
    "    \n",
    "    # Ajustamos el modelo\n",
    "    possible_scores = [1,2]\n",
    "    user_ids = list(range(0,350))  # Lista de ID de usuarios\n",
    "    item_ids = [1,2,3,4,5,6,7]  # Lista de ID de elementos\n",
    "    num_factors = 10\n",
    "    num_iters = 100\n",
    "    learning_rate = 0.02 \n",
    "    regularisation = 0.1\n",
    "    seed = 42\n",
    "\n",
    "    bemf_model = BeMF(possible_scores, ratings_matrix_u, user_ids, item_ids, num_factors, num_iters, learning_rate, regularisation, seed)\n",
    "    \n",
    "    # Actualizaciones del proceso\n",
    "    bemf_model.fit(verbose=True)\n",
    "    \n",
    "    # predicción \n",
    "    prediction = bemf_model.predict(0, item -1)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c90fc",
   "metadata": {},
   "source": [
    "## Estuadiamos el rendimiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324de0f3",
   "metadata": {},
   "source": [
    "### Accuracy True/False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca2bf26",
   "metadata": {},
   "source": [
    "Calculamos la mtriz de valoraciones general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241968d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix_general = crear_ratings_matrix(df_datos[['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0c35a",
   "metadata": {},
   "source": [
    "Estudiamos el redimiento calculando la predicción sobre las valoraciones de las que ya tenemos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b5ef1",
   "metadata": {},
   "source": [
    "## Automatizamos la evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e330db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(ratings_matrix_general,df_para_usuarios_similares, n_usuarios):\n",
    "    accuracies = []\n",
    "    confusion_matrix = np.zeros((2, 2), dtype=int)\n",
    "    TP= 0\n",
    "    FP= 0\n",
    "    FN = 0\n",
    "    \n",
    "    for u in range(n_usuarios):\n",
    "        for i in range(7):\n",
    "            valor_real = ratings_matrix_general[u][i]\n",
    "            if valor_real != None:\n",
    "                prediction =prediccion(u,i+1,df_para_usuarios_similares)\n",
    "                print('valor',valor_real)\n",
    "                print('prediccion',prediction)\n",
    "                accuracies.append(prediction==valor_real)\n",
    "                confusion_matrix[valor_real - 1, prediction - 1] += 1\n",
    "                \n",
    "                if (valor_real == 2) &(prediction == 2):\n",
    "                    TP +=1\n",
    "                elif (valor_real == 1) &(prediction == 2):\n",
    "                    FP +=1\n",
    "                elif(valor_real == 2) &(prediction == 1):\n",
    "                    FN +=1\n",
    "                    \n",
    "    confusion_matrix_percent = np.round(confusion_matrix.astype(float) / confusion_matrix.sum(axis=1, keepdims=True) * 100, 2)\n",
    "    acc = accuracies.count(True)*100/len(accuracies)\n",
    "    \n",
    "    # F1 score\n",
    "    F1 = TP/(TP+0.5*(FP+FN))\n",
    "    \n",
    "    # Configurar el formato de impresión\n",
    "    np.set_printoptions(formatter={'float': lambda x: \"{:.2f}\".format(x)})\n",
    "\n",
    "    return acc,confusion_matrix_percent,F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5bc884",
   "metadata": {},
   "source": [
    "# Evaluación del sistema sobre un muestreo aleatorio\n",
    "Para seleccionar un subconjunto aleatorio, utilizamos la función sample() de pandas.El parámetro \"n\" indica el número de muestras aleatorias que deseas seleccionar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cfdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datos_subset = df_datos.sample(n=100).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecdf792",
   "metadata": {},
   "source": [
    "Evaluamos el modelo sobre el subconjunto de datos seleccionado. Utilizamos aún así el conjunto de datos completo para calcular los usuarios similares de cada usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ddfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix_general_subset = crear_ratings_matrix(df_datos_subset[['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83a5b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluar_modelo(ratings_matrix_general=ratings_matrix_general_subset,df_para_usuarios_similares = df_datos, n_usuarios=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a4f65",
   "metadata": {},
   "source": [
    "# Evaluación sobre los usuarios más activos\n",
    "Calculamos el número de evaluaciones que ha realizado cada usuario. Tomaremos solo aquellos usuarios que hayan valorado más de tres items para llevar a cabo la evaluación de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos una variable que indica el número de evaluaciones realizadas por cada usuario\n",
    "df_datos['num_evaluations'] = df_datos[['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']].notnull().sum(axis=1)\n",
    "\n",
    "# Tomamos solo aquellos usuarios con más de tres valoraciones.\n",
    "df_datos_mas3_valoraciones =df_datos[df_datos['num_evaluations']>3][['Comunidad Autónoma', 'Edad', 'Procedencia', 'Sexo',\n",
    "       'Situación de dependencia', 'Sector económico', 'Renta anual neta',\n",
    "       'Estado civil', 'Número de hijos', 'T.1.', 'T.2.', 'T.3.', 'T.4.',\n",
    "       'T.5.', 'T.6.', 'T.7.']].reset_index()\n",
    "\n",
    "# Tomamos un subconjunto de los usuarios más activos\n",
    "df_activos_subset = df_datos_mas3_valoraciones.sample(n=100).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a1dab",
   "metadata": {},
   "source": [
    "Evaluamos el modelo sobre el subconjunto de datos seleccionado. Utilizamos el conjunto de usuarios más activos para calcular los usuarios similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix_activos_subset = crear_ratings_matrix(df_activos_subset[['T.1.', 'T.2.', 'T.3.', 'T.4.','T.5.', 'T.6.', 'T.7.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_modelo(ratings_matrix_general=ratings_matrix_activos_subset,df_para_usuarios_similares = df_datos_mas3_valoraciones, n_usuarios=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79215d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
